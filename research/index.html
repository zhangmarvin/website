<!DOCTYPE HTML>

<html>
<head>
    <meta charset="utf-8">
    <title>Research - Marvin Zhang</title>
    <link href='http://fonts.googleapis.com/css?family=Oxygen:400,300,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="/css/style.css">
    <link rel="shortcut icon" href="/misc/favicon.ico">
</head>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-54050540-1', 'auto');
  ga('send', 'pageview');

</script>
<body>
    <div id="header">
        <div class="home"><a class="link" href="/">marvin zhang</a></div>
        <div class="links">
            <a class="link" href="/teaching">teaching</a>&nbsp;/&nbsp;<a class="link" href="/projects">projects</a>&nbsp;/&nbsp;<a class="link" href="/other">other</a>
        </div>
    </div>
    <br>
    <h2>research</h2>
    <p>
    Currently, I am an undergraduate research apprentice in Professor
    <a class="link" href="http://www.cs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>'s
    <a class="link" href="http://rll.berkeley.edu/outreach/">Robot Learning Lab</a>,
    and I work primarily with post-doctoral researcher
    <a class="link" href="http://www.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>.
    </p>
    <p>
    My work is focused on developing new and existing machine learning
    techniques and algorithms that can allow robots to discover and learn
    complex and intelligent behavior. Recently, I've been working mainly on
    guided policy search as well as recurrent neural networks, and exploring
    possible benefits and improvements that can result from this combination.
    Earlier on, I worked to develop a framework for easily and massively
    parallelizing reinforcement learning algorithms across computing clusters.
    </p>
    <div id="publications">
        <h3>publications</h3>
        <table>
            <tr>
                <td>
                    <a href="http://arxiv.org/abs/1507.01273"><img src="/misc/rnn.png"/></a>
                </td>
                <td>
                    <a class="link" href="http://arxiv.org/abs/1507.01273">
                    <h4>Marvin Zhang, Sergey Levine, Zoe McCarthy, Chelsea Finn, Pieter Abbeel. 
                    <i>Policy Learning with Continuous Memory States for Partially Observed Robotic Control</i>. 
                    2015. arXiv 1507.01273.</h4>
                    </a>
                    <p>
                    In this paper, we use the guided policy search algorithm to
                    train a policy with internal continuous memory states, which
                    can be understood as a type of recurrent neural network. We
                    show that this policy can successfully and efficiently
                    complete several simulated tasks that either require memory
                    or can be made easier by the use of memory. We compare our
                    method a regular feedforward neural network, a memoryless
                    policy, and an LSTM neural network, a policy that has
                    memory, and show that our method outperforms both.
                    </p>
                </td>
            </tr>
        </table>
        <div id="software">
            <h3>software</h3>
            <p>
            <a class="link" href="https://github.com/zhangmarvin/parRL">parRL</a>
            is a framework for parallelizing reinforcement learning across
            computing clusters that I developed alongside PhD student
            <a class="link" href="http://www.eecs.berkeley.edu/~joschu/">John Schulman</a>.
            the main goals were for the framework to be lightweight, robust,
            simple, and scalable, and to work around as much of the
            unreliability surrounding parallelism as possible, without
            compromising on the goals of the system. Tools used in the
            architecture include
            <a class="link" href="https://cloud.google.com/">Google Cloud Platform</a>, 
            <a class="link" href="http://zeromq.org/">ZeroMQ</a>, and
            <a class="link" href="https://docs.python.org/2/library/xmlrpclib.html">XMLRPCLib</a>.
            </p>
            <p>
            I am also currently collaborating on a project to write a new
            codebase for guided policy search, and we are hoping to open source
            this soon.
            </p>
</body>
</html>
