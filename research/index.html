<!DOCTYPE HTML>

<html>
<head>
    <meta charset="utf-8">
    <title>Research - Marvin Zhang</title>
    <link href='http://fonts.googleapis.com/css?family=Oxygen:400,300,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="/css/style.css">
    <link rel="shortcut icon" href="/misc/favicon.ico">
</head>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-54050540-1', 'auto');
  ga('send', 'pageview');

</script>
<body>
    <div id="header">
        <div class="home"><a class="link" href="/">marvin zhang</a></div>
        <div class="links">
            <a class="link" href="/teaching">teaching</a>&nbsp;/&nbsp;<a class="link" href="/projects">projects</a>&nbsp;/&nbsp;<a class="link" href="/other">other</a>
        </div>
    </div>
    <br>
    <h2>research</h2>
    <p>
    I am an undergraduate research apprentice (research assistant) in Professor
    <a class="link" href="http://www.cs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>'s
    <a class="link" href="http://rll.berkeley.edu/outreach/">Robot Learning Lab</a>,
    and I work primarily with post-doctoral researcher (now Professor!)
    <a class="link" href="http://www.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>.
    </p>
    <p>
    My work is focused on developing machine learning methods and algorithms
    that can allow robots discover and learn complex and intelligent behavior.
    Recently, I've been interested in deep learning and its potential
    applications to robotic control. To this end, I'm working on projects
    focused on learning deep control policies with memory capabilities, as well
    as exploring deep learning for 
    <a class="link" href="https://www.youtube.com/watch?v=Hqn4AEfn_qg">new robotic domains</a>.
    Earlier on, I developed a framework for easily and massively parallelizing
    reinforcement learning algorithms across computing clusters. For more
    details, refer to my <a class="link" href="/misc/cv.pdf">CV</a>.
    </p>
    <div id="publications">
        <h3>publications</h3>
        <table>
            <tr>
                <td>
                    <a href="http://arxiv.org/abs/1507.01273"><img src="/misc/rnn.png"/></a>
                </td>
                <td>
                    <a class="link" href="http://arxiv.org/abs/1507.01273">
                    <h4>Marvin Zhang, Zoe McCarthy, Chelsea Finn, Sergey Levine, Pieter Abbeel.
                    <b>Learning Deep Neural Network Policies with Continuous Memory States.</b>
                    <i>To be presented at ICRA 2016. arXiv 1507.01273.</i></h4>
                    </a>
                    <p>
                    In this paper, we use the guided policy search algorithm to
                    train control policies with continuous memory states, which
                    can be understood as a type of recurrent neural network. We
                    show that this policy can successfully and efficiently
                    complete several simulated tasks that either require memory
                    or can be made easier by the use of memory. We compare our
                    method to several other baselines, and show that our method
                    outperforms all of these alternate approaches.
                    </p>
                </td>
            </tr>
        </table>
    </div>
    <div id="presentations">
        <h3>presentations</h3>
        <ul>
            <li>
                I gave a talk at
                <a class="link" href="https://nips.cc/">NIPS 2015</a> in the
                <a class="link" href="http://www.thespermwhale.com/jaseweston/ram/">Reasoning, Attention, Memory (RAM) Workshop</a>
                on my recent work in training policies with memory.
                Unfortunately, the workshop was not recorded, but my slides are
                available
                <a class="link" href="http://www.thespermwhale.com/jaseweston/ram/slides/session4/ram_talk_zhang_marvin.pdf">here</a>.
                The workshop was
                <a class="link" href="https://www.facebook.com/photo.php?fbid=1626023934328466">packed to the brim</a>!
            </li>
            <li>
                I also gave a much shorter spotlight talk and poster
                presentation on the same work at the
                <a class="link" href="http://rll.berkeley.edu/deeprlworkshop/">Deep Reinforcement Learning Workshop</a>.
                A recording of this talk should be available shortly.
            </li>
        </ul>
    </div>
    <div id="software">
        <h3>software</h3>
        <ul>
            <li>
                <a class="link" href="http://rll.berkeley.edu/gps/">GPS</a> is a
                standard, open-source implementation of the guided policy search
                algorithm, developed by several member of the Robot Learning
                Lab. The goal of this project is to allow other researchers to
                understand, use, and extend guided policy search in their own
                research.
            </li>
            <li>
                <a class="link" href="https://github.com/zhangmarvin/parRL">parRL</a>
                is a framework for parallelizing reinforcement learning across
                computing clusters that I developed alongside PhD student
                <a class="link" href="http://www.eecs.berkeley.edu/~joschu/">John Schulman</a>.
                The main goals were for the framework to be lightweight, robust,
                simple, and scalable.
            </li>
        </ul>
    </div>
</body>
</html>
